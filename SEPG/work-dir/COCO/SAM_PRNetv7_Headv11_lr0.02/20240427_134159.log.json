{"env_info": "sys.platform: linux\nPython: 3.7.10 (default, Jun  4 2021, 14:48:32) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1,2,3: NVIDIA GeForce RTX 4090\nCUDA_HOME: /usr/local/cuda-12.0\nNVCC: Build cuda_12.0.r12.0/compiler.32267302_0\nGCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\nPyTorch: 1.7.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.0\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 8.0.3\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.0\nOpenCV: 4.5.5\nMMCV: 1.3.16\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.0\nMMDetection: 2.13.0+", "config": "checkpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\nnorm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\ndebug = False\nnum_stages = 2\nmodel = dict(\n    type='SAM_PRNetv7',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=0,\n        add_extra_convs='on_input',\n        num_outs=4,\n        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),\n    roi_head=dict(\n        type='HMILHeadv11',\n        num_stages=2,\n        top_k1=1,\n        top_k2=4,\n        with_atten=False,\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=dict(\n            type='MSEMILHeadv7',\n            num_stages=2,\n            with_loss_pseudo=False,\n            in_channels=256,\n            fc_out_channels=1024,\n            roi_feat_size=7,\n            num_classes=80,\n            num_ref_fcs=0,\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0.0, 0.0, 0.0, 0.0],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=True,\n            loss_type='MIL',\n            loss_mil1=dict(\n                type='MILLoss',\n                binary_ins=False,\n                loss_weight=0.25,\n                loss_type='binary_cross_entropy'),\n            loss_mil2=dict(\n                type='MILLoss',\n                binary_ins=False,\n                loss_weight=0.25,\n                loss_type='gfocal_loss'))),\n    train_cfg=dict(\n        base_proposal=dict(\n            gen_proposal_mode='fix_gen',\n            cut_mode=None,\n            base_scales=[0.5, 0.3333333333333333, 1.0, 2.0, 3.0],\n            base_ratios=[1.0, 1.05, 1.1, 1.2, 0.83, 0.9, 0.95],\n            shake_ratio=None,\n            iou_thr=0.3),\n        fine_proposal=dict(\n            gen_proposal_mode='fix_gen',\n            cut_mode=None,\n            shake_ratio=[0.1],\n            base_ratios=[1, 1.2, 1.3, 1.4, 0.9, 0.8, 0.7],\n            iou_thr=0.3,\n            gen_num_neg=500),\n        rcnn=None),\n    test_cfg=dict(rpn=None, rcnn=None))\ndataset_type = 'CocoFmtDataset'\ndata_root = '/home/ps/Guo/Project/P2BNet-main/TOV_mmdetection/data/COCO/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(\n        type='Resize',\n        img_scale=[(2000, 480), (2000, 576), (2000, 688), (2000, 864),\n                   (2000, 1000), (2000, 1200)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=[\n            'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n            'gt_true_bboxes'\n        ])\n]\ntest_scale = 1200\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(2000, 1200),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_anns_id', 'gt_true_bboxes'\n                ])\n        ])\n]\ndata = dict(\n    samples_per_gpu=4,\n    workers_per_gpu=1,\n    shuffle=None,\n    train=dict(\n        type='CocoFmtDataset',\n        ann_file=\n        '/home/ps/Guo/Project/P2BNet-main/TOV_mmdetection/data/COCO/annotations/instances_train2017_coarse_proposal_v2_adjust_centers.json',\n        img_prefix=\n        '/home/ps/Guo/Project/P2BNet-main/TOV_mmdetection/data/COCO/train2017/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='Resize',\n                img_scale=[(2000, 480), (2000, 576), (2000, 688), (2000, 864),\n                           (2000, 1000), (2000, 1200)],\n                multiscale_mode='value',\n                keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_true_bboxes'\n                ])\n        ]),\n    val=dict(\n        samples_per_gpu=4,\n        type='CocoFmtDataset',\n        ann_file=\n        '/home/ps/Guo/Project/P2BNet-main/TOV_mmdetection/data/COCO/annotations/instances_train2017_coarse_proposal_v2_adjust_centers.json',\n        img_prefix=\n        '/home/ps/Guo/Project/P2BNet-main/TOV_mmdetection/data/COCO/train2017/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2000, 1200),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='DefaultFormatBundle'),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_anns_id', 'gt_true_bboxes'\n                        ])\n                ])\n        ],\n        test_mode=False),\n    test=dict(\n        type='CocoFmtDataset',\n        ann_file=\n        '/home/ps/Guo/Project/P2BNet-main/TOV_mmdetection/data/COCO/annotations/instances_val2017.json',\n        img_prefix=\n        '/home/ps/Guo/Project/P2BNet-main/TOV_mmdetection/data/COCO/val2017/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2000, 1200),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='DefaultFormatBundle'),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_anns_id', 'gt_true_bboxes'\n                        ])\n                ])\n        ]))\ncheck = dict(stop_while_nan=False)\noptimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\nrunner = dict(type='EpochBasedRunner', max_epochs=12)\nwork_dir = 'work-dir/COCO/SAM_PRNetv7_Headv11_lr0.02/'\nevaluation = dict(\n    interval=12,\n    metric='bbox',\n    save_result_file=\n    'work-dir/COCO/MobileSAM_PRNetv7_Headv11_MSEv7_2iter/3iter_12poch_1200_6epoch_result.json',\n    do_first_eval=False,\n    do_final_eval=True)\ngpu_ids = range(0, 4)\n", "seed": null, "exp_name": "sepg_r50_fpn_1x_coco_ms.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.00198, "memory": 14308, "data_time": 0.30384, "stage0_loss_instance_mil": 1.51419, "stage0_bag_acc": 18.13375, "stage0_mean_ious": 0.26943, "stage0_s": 0.16395, "stage0_m": 0.21782, "stage0_l": 0.25092, "stage0_h": 0.28241, "stage1_loss_instance_mil": 0.0187, "stage1_bag_acc": 1.05255, "stage1_neg_loss": 8e-05, "stage1_mean_ious": 0.2628, "stage1_s": 0.15946, "stage1_m": 0.21562, "stage1_l": 0.24411, "stage1_h": 0.27432, "loss": 1.53297, "grad_norm": 0.71961, "time": 0.96664}
